{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49141089-9351-4b5f-a87d-a76cbe355d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del array: 50000000\n",
      "\n",
      "Tiempo para la operación de reducción secuencial:\n",
      "Medicion de tiempo usando numpy.sum(): 19.2 ms ± 8.13 µs per loop (mean ± std. dev. of 2 runs, 100 loops each)\n",
      "Resultado de la suma secuencial: 25002132.539449412\n",
      "\n",
      "\n",
      "Tiempo para la operación de reducción con 1 procesos:\n",
      "Medicion de tiempo usando 1 processes: 353 ms ± 2.59 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Resultado de la suma con 1 procesos: 25002132.539449412\n",
      "\n",
      "Tiempo para la operación de reducción con 2 procesos:\n",
      "Medicion de tiempo usando 2 processes: 675 ms ± 5.38 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Resultado de la suma con 2 procesos: 25002132.53944942\n",
      "\n",
      "Tiempo para la operación de reducción con 4 procesos:\n",
      "Medicion de tiempo usando 4 processes: 1.32 s ± 11.8 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Resultado de la suma con 4 procesos: 25002132.539449368\n"
     ]
    }
   ],
   "source": [
    "#3.4.1 Con respecto a la librería multiprocessing, utilizar la función starmap para crear los procesos que se van a ejecutar en paralelo.\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time \n",
    "\n",
    "# Modificamos la función de reducción para aceptar un inicio y fin\n",
    "def sum_multiprocessing(A, ini, fin):\n",
    "    return np.sum(A[ini:fin])\n",
    "\n",
    "# Secuencial\n",
    "value = 5 * 10** 7  # Tamaño del array\n",
    "X = np.random.rand(value)  # Array con valores aleatorios\n",
    "print(f\"Tamaño del array: {X.size}\\n\")\n",
    "\n",
    "# Tiempo secuencial\n",
    "print(\"Tiempo para la operación de reducción secuencial:\")\n",
    "tiempo = %timeit -r 2 -o -q np.sum(X)\n",
    "print(f\"Medicion de tiempo usando numpy.sum(): {tiempo}\")\n",
    "print(f\"Resultado de la suma secuencial: {np.sum(X)}\\n\")\n",
    "\n",
    "\n",
    "# Divisiones del array para multiprocessing\n",
    "def dividir_array(value, num_procesos):\n",
    "    if num_procesos == 1:\n",
    "        return [(0, value)]  # Una sola partición [0, value]\n",
    "    elif num_procesos == 2:\n",
    "        mitad = int(value / 2)\n",
    "        return [(0, mitad), (mitad, value)]  # Dos particiones [0, mitad] y [mitad, value]\n",
    "    elif num_procesos == 4:\n",
    "        cuarto = int(value / 4)\n",
    "        mitad = int(value / 2)\n",
    "        tres_cuartos = int(3 * value / 4)\n",
    "        return [(0, cuarto), (cuarto, mitad), (mitad, tres_cuartos), (tres_cuartos, value)]  # Cuatro particiones\n",
    "    else:\n",
    "        raise ValueError(\"Número de procesos no soportado. Use 1, 2 o 4.\")\n",
    "\n",
    "# Utilizando multiprocessing con 1, 2 y 4 procesos\n",
    "for num_procesos in [1, 2, 4]:\n",
    "    print(f\"\\nTiempo para la operación de reducción con {num_procesos} procesos:\")\n",
    "\n",
    "    # Dividimos el array según el número de procesos\n",
    "    rangos = dividir_array(value, num_procesos)\n",
    "\n",
    "    # Definimos la función que ejecutará multiprocessing\n",
    "    def run_parallel_reduction():\n",
    "        with Pool(processes=num_procesos) as pool:\n",
    "            # Usamos starmap para aplicar sum_multiprocessing a cada rango\n",
    "            resultados = pool.starmap(sum_multiprocessing, [(X, ini, fin) for (ini, fin) in rangos])\n",
    "        return sum(resultados)\n",
    "\n",
    "    # Medimos el tiempo usando %timeit\n",
    "    tiempo = %timeit -r 2 -o -q run_parallel_reduction()\n",
    "    resultado = run_parallel_reduction()\n",
    "\n",
    "    print(f\"Medicion de tiempo usando {num_procesos} processes: {tiempo}\")\n",
    "    print(f\"Resultado de la suma con {num_procesos} procesos: {resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c543eec4-2580-46de-ba4c-bed6989e96a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del array: 50000000\n",
      "\n",
      "Tiempo de transferencia a la GPU: 41026.35 µs\n",
      "Tiempo usando cupy.sum(): 134.71 µs\n",
      "Resultado de la suma usando cupy.sum(): 24997542.0\n",
      "\n",
      "Resultado en la CPU después de transferir desde la GPU: 24997542.0\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Crear el array en la CPU usando numpy\n",
    "value = 5 * 10**7  # Tamaño del array\n",
    "X_cpu = np.random.rand(value).astype(np.float32)  # Array en la CPU con valores aleatorios\n",
    "print(f\"Tamaño del array: {X_cpu.size}\\n\")\n",
    "\n",
    "# Medir el tiempo de la transferencia de datos a la GPU\n",
    "start_transfer_time = time.time()\n",
    "\n",
    "# Copiar el array a la GPU usando cupy\n",
    "X_gpu = cp.asarray(X_cpu)\n",
    "\n",
    "end_transfer_time = time.time()\n",
    "transfer_time = (end_transfer_time - start_transfer_time) * 1e6  # Convertir a microsegundos\n",
    "\n",
    "# Medir el tiempo de la operación de reducción en la GPU\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la suma en la GPU usando cupy\n",
    "result_cupy_sum = cp.sum(X_gpu)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecución de la suma en la GPU\n",
    "time_taken = (end_time - start_time) * 1e6  # Convertir a microsegundos\n",
    "\n",
    "# Copiar el resultado de vuelta a la CPU\n",
    "result_cpu = cp.asnumpy(result_cupy_sum)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Tiempo de transferencia a la GPU: {transfer_time:.2f} µs\")\n",
    "print(f\"Tiempo usando cupy.sum(): {time_taken:.2f} µs\")\n",
    "print(f\"Resultado de la suma usando cupy.sum(): {result_cupy_sum}\\n\")\n",
    "\n",
    "# Verificar que el resultado es el mismo que en la CPU\n",
    "print(f\"Resultado en la CPU después de transferir desde la GPU: {result_cpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9861f695-e3f0-41da-92a3-ec6902e89718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del array: 50000000\n",
      "\n",
      "Medicion de tiempo usando  Numba parallel_reduce: 0.240501 seconds\n",
      "Resultado de la suma usando Numba parallel_reduce: 24999669.644815106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Crear el array en la CPU usando numpy\n",
    "value = 5 * 10**7  # Tamaño del array\n",
    "X_cpu = np.random.rand(value)  # Array en la CPU con valores aleatorios\n",
    "print(f\"Tamaño del array: {X_cpu.size}\\n\")\n",
    "# Definir una función de reducción paralela usando numba.njit\n",
    "@numba.njit(parallel=True)\n",
    "def parallel_reduce(array):\n",
    "    total = 0.0\n",
    "    for i in numba.prange(array.size):  # Paralelizar el bucle con prange\n",
    "        total += array[i]\n",
    "    return total\n",
    "\n",
    "# Medir el tiempo de ejecución de la reducción en la CPU con numba\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la reducción\n",
    "result_numba_sum = parallel_reduce(X_cpu)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(f\"Medicion de tiempo usando  Numba parallel_reduce: {time_taken:.6f} seconds\")\n",
    "print(f\"Resultado de la suma usando Numba parallel_reduce: {result_numba_sum}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845b23a-f3bb-44dd-87f6-88d620d5f916",
   "metadata": {},
   "source": [
    "RESULTADO: los resultados obtenidos indican que para maximizar la velocidad en CPU, numpy.sum() sigue siendo la opción más rápida; cuando disponemos de la GPU, CuPy demostró ser el más eficiente; pero si no se tiene acceso a una GPU Numba parallel_reduce, ofrece una mejora significativa frente a las versiones multiproceso (que empeoran a medida que se agregan procesos)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
